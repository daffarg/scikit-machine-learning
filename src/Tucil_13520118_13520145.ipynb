{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import six\n",
    "import sys\n",
    "sys.modules['sklearn.externals.six'] = six\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, f1_score, recall_score, confusion_matrix\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split, cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier, export_text\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "from id3 import Id3Estimator\n",
    "import id3.export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569\n",
      "114\n",
      "455\n",
      "test 0.20035149384885764\n",
      "train 0.7996485061511424\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    TASK 1\n",
    "    Membaca dataset breast cancer\n",
    "'''\n",
    "\n",
    "# load dataset\n",
    "data = load_breast_cancer()\n",
    "\n",
    "df = pd.DataFrame(data.data, columns=data.feature_names)\n",
    "df['target'] = data.target\n",
    "\n",
    "# Seperate feature and target\n",
    "feat = df.iloc[:, :-1]\n",
    "target = df['target']\n",
    "\n",
    "# Check value for target function and feature\n",
    "# print(\"x_bc\", x_bc[:5])\n",
    "# print(\"y_bc\", y_bc.unique())\n",
    "\n",
    "\n",
    "# Separate datasets into 80% training data and 20% test data\n",
    "data_train, data_test, target_train, target_test = train_test_split(feat, target, test_size=0.2, random_state=420)\n",
    "\n",
    "'''\n",
    "    OUTPUT:\n",
    "    data_train: data yang digunakan sebagai data training\n",
    "    data_test: data yang digunakan sebagai data testing\n",
    "    target_train: target atau label yang sesuai dengan data training\n",
    "    target_test: target atau label yang sesuai dengan data testing\n",
    "\n",
    "    INPUT:\n",
    "    feat: atribut dari dataset yang akan dibagi menjadi data training dan data testing\n",
    "    target: target atau label dari dataset yang akan dibagi menjadi data training dan data testing\n",
    "    test_size=0.2: ukuran data testing, di sini diatur sebesar 20% dari seluruh dataset\n",
    "    random_state=42: seed atau biji acak yang digunakan untuk memastikan hasil pengacakan selalu sama setiap kali kode dijalankan, \n",
    "    sehingga hasil yang diperoleh dapat direproduksi.\n",
    "'''\n",
    "\n",
    "#Checking the result\n",
    "print(len(data.data)) \n",
    "print(len(data_test))\n",
    "print(len(data_train))\n",
    "print('test',len(data_test)/len(data.data))\n",
    "print('train',len(data_train)/len(data.data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "Function for a train and prediction\n",
    "->def get_predictions(model,data_train, target_train, data_test)\n",
    "    param for input :\n",
    "    1. model -> learning model\n",
    "    2. data_train -> data training\n",
    "    3. target_train -> target training \n",
    "    4. data_test  -> data test\n",
    "    This function will return the prediction of    \n",
    "-> def get_score(model, data_train, target_train, data_test, target_test)\n",
    "    param for input :\n",
    "    1. model -> learning model\n",
    "    2. data_train -> data training\n",
    "    3. target_train -> target training\n",
    "    4. data_test -> data test\n",
    "    5. target_test -> target training\n",
    "    This function will return the value of all the accuracy score and f1_score of the entire prediction \n",
    "    as dictionary\n",
    "'''\n",
    "\n",
    "def get_prediction(model, model_name, data_train, target_train, data_test):\n",
    "    model  = model.fit(data_train, target_train)\n",
    "    save_to_pickle(model, model_name)\n",
    "    pickle_model=load(model,model_name)\n",
    "    return pickle_model.predict(data_test)\n",
    "\n",
    "def save_to_pickle(model,filename):\n",
    "    with open(filename, 'wb') as file:\n",
    "        pickle.dump(model,file)\n",
    "def load(model,filename):\n",
    "    with open(filename, 'rb') as file:\n",
    "        pickle_model= pickle.load(file)\n",
    "    return pickle_model\n",
    "        \n",
    "def get_score(model, model_name, data_train, target_train, data_test, target_test):\n",
    "    prediction = get_prediction(model, model_name, data_train, target_train, data_test)\n",
    "    return {\n",
    "        \"accuracy_score\": accuracy_score(target_test, prediction),\n",
    "        \"precision_score\": precision_score(target_test, prediction),\n",
    "        \"recall_score\": recall_score(target_test, prediction),\n",
    "        \"f1_score\": f1_score(target_test, prediction, average='micro'),\n",
    "        \"confusion_matrix\": confusion_matrix(target_test, prediction)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.9736842105263158, 'precision_score': 0.9710144927536232, 'recall_score': 0.9852941176470589, 'f1_score': 0.9736842105263158, 'confusion_matrix': array([[44,  2],\n",
      "       [ 1, 67]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    DECISION TREE CLASSIFIER\n",
    "\n",
    "    Create learning model with decision tree classfier\n",
    "    Train the data and get score\n",
    "\n",
    "    Param:\n",
    "    1. criterion = entropy -> use Information Gain measurement in selecting \n",
    "    the best feature for splitting\n",
    "    2. max_features = auto ->  select the best feature considering the square root \n",
    "    of the number of features\n",
    "    3. random state -> set seed for the algorithm's randomization\n",
    "'''\n",
    "\n",
    "dtl = DecisionTreeClassifier(criterion=\"entropy\", max_features=\"auto\", random_state=33)\n",
    "\n",
    "dt_score = get_score(dtl, \"DTL.pkl\", data_train, target_train, data_test, target_test)\n",
    "print(dt_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|--- feature_23 <= 884.75\n",
      "|   |--- feature_6 <= 0.09\n",
      "|   |   |--- feature_12 <= 4.12\n",
      "|   |   |   |--- feature_28 <= 0.35\n",
      "|   |   |   |   |--- feature_27 <= 0.13\n",
      "|   |   |   |   |   |--- feature_18 <= 0.02\n",
      "|   |   |   |   |   |   |--- feature_21 <= 33.10\n",
      "|   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |   |--- feature_21 >  33.10\n",
      "|   |   |   |   |   |   |   |--- feature_21 <= 33.56\n",
      "|   |   |   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |   |   |--- feature_21 >  33.56\n",
      "|   |   |   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |   |--- feature_18 >  0.02\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_27 >  0.13\n",
      "|   |   |   |   |   |--- feature_28 <= 0.26\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_28 >  0.26\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_28 >  0.35\n",
      "|   |   |   |   |--- feature_26 <= 0.36\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_26 >  0.36\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |--- feature_12 >  4.12\n",
      "|   |   |   |--- feature_19 <= 0.00\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_19 >  0.00\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |--- feature_6 >  0.09\n",
      "|   |   |--- feature_21 <= 25.74\n",
      "|   |   |   |--- feature_24 <= 0.15\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_24 >  0.15\n",
      "|   |   |   |   |--- feature_23 <= 678.25\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_23 >  678.25\n",
      "|   |   |   |   |   |--- feature_3 <= 674.80\n",
      "|   |   |   |   |   |   |--- class: 0\n",
      "|   |   |   |   |   |--- feature_3 >  674.80\n",
      "|   |   |   |   |   |   |--- class: 1\n",
      "|   |   |--- feature_21 >  25.74\n",
      "|   |   |   |--- feature_4 <= 0.10\n",
      "|   |   |   |   |--- feature_7 <= 0.05\n",
      "|   |   |   |   |   |--- class: 1\n",
      "|   |   |   |   |--- feature_7 >  0.05\n",
      "|   |   |   |   |   |--- class: 0\n",
      "|   |   |   |--- feature_4 >  0.10\n",
      "|   |   |   |   |--- class: 0\n",
      "|--- feature_23 >  884.75\n",
      "|   |--- feature_27 <= 0.14\n",
      "|   |   |--- feature_21 <= 19.91\n",
      "|   |   |   |--- class: 1\n",
      "|   |   |--- feature_21 >  19.91\n",
      "|   |   |   |--- feature_8 <= 0.15\n",
      "|   |   |   |   |--- class: 1\n",
      "|   |   |   |--- feature_8 >  0.15\n",
      "|   |   |   |   |--- class: 0\n",
      "|   |--- feature_27 >  0.14\n",
      "|   |   |--- class: 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Show Tree Model (DTL)\n",
    "'''\n",
    "\n",
    "print(export_text(dtl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.956140350877193, 'precision_score': 0.9565217391304348, 'recall_score': 0.9705882352941176, 'f1_score': 0.956140350877193, 'confusion_matrix': array([[43,  3],\n",
      "       [ 2, 66]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    ID3\n",
    "\n",
    "    Create learning model with ID3\n",
    "    Train the data and get score\n",
    "\n",
    "    Param:\n",
    "    1. prune = True -> the resulting decision tree will be pruned to prevent overfitting\n",
    "    2. gain_ratio = True -> use the gain ratio metric to measure the information \n",
    "    value of each feature in splitting the dataset\n",
    "'''\n",
    "\n",
    "id3 = Id3Estimator(prune=True, gain_ratio=True)\n",
    "id3_score = get_score(id3, \"ID3.pkl\", data_train, target_train, data_test, target_test)\n",
    "\n",
    "print(id3_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.868421052631579, 'precision_score': 0.8271604938271605, 'recall_score': 0.9852941176470589, 'f1_score': 0.868421052631579, 'confusion_matrix': array([[32, 14],\n",
      "       [ 1, 67]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    K-Means\n",
    "\n",
    "    Create learning model with K-Means\n",
    "    Train the data and get score\n",
    "\n",
    "    Param:\n",
    "    1. n_cluesters = 2 -> number of clusters = 2\n",
    "    2. max_iter = 10000 -> maximum number of iterations the K-Means algorithm = 10000\n",
    "    3. random_state = 13 ->  seed for the random number generator used by the K-Means algorithm = 13\n",
    "'''\n",
    "\n",
    "kmeans = KMeans(n_clusters=2, max_iter=10000, random_state=13) \n",
    "kmeans_score = get_score(kmeans, \"K-MEANS.pkl\", data_train, target_train, data_test, target_test)\n",
    "\n",
    "print(kmeans_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.9473684210526315, 'precision_score': 0.9558823529411765, 'recall_score': 0.9558823529411765, 'f1_score': 0.9473684210526315, 'confusion_matrix': array([[43,  3],\n",
      "       [ 3, 65]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Logistic Regression\n",
    "\n",
    "    Create learning model with K-Means\n",
    "    Train the data and get score\n",
    "    Param :\n",
    "    max_iter = 10000 -> maximum number of iterations the Logistic Regression algorithm \n",
    "\n",
    "'''\n",
    "\n",
    "logres = LogisticRegression(max_iter=10000)\n",
    "logres_score = get_score(logres,'LOGRES.pkl', data_train, target_train, data_test, target_test)\n",
    "\n",
    "print(logres_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.956140350877193, 'precision_score': 0.9846153846153847, 'recall_score': 0.9411764705882353, 'f1_score': 0.956140350877193, 'confusion_matrix': array([[45,  1],\n",
      "       [ 4, 64]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Multilayer Perceptron (MLP)\n",
    "\n",
    "    Create learning model with K-Means\n",
    "    Train the data and get score\n",
    "\n",
    "    Param:\n",
    "    1. n_cluesters = 50000 -> maximum number of iterations for the solver to converge = 50000\n",
    "    2. solver = lbfgs -> optimization solver algorithm to be used = lbfgs\n",
    "    The 'lbfgs' solver is used to optimize the weights and bias parameters of the network\n",
    "\n",
    "     \"Limited-memory Broyden-Fletcher-Goldfarb-Shanno\" \n",
    "     and is a quasi-Newton method to approximate the Newton-Raphson algorithm.\n",
    "\n",
    "'''\n",
    "\n",
    "mlp = MLPClassifier(max_iter=10000000, solver=\"lbfgs\")\n",
    "mlp_score = get_score(mlp,'MLP.pkl',data_train, target_train, data_test, target_test)\n",
    "\n",
    "print(mlp_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy_score': 0.9649122807017544, 'precision_score': 0.9705882352941176, 'recall_score': 0.9705882352941176, 'f1_score': 0.9649122807017544, 'confusion_matrix': array([[44,  2],\n",
      "       [ 2, 66]], dtype=int64)}\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Support Vector Machine (SVM)\n",
    "\n",
    "    Create learning model with SVM\n",
    "    Train the data and get score\n",
    "\n",
    "    Param:\n",
    "    1. kernel = linear -> linear decision boundary will be used to separate the data into classes\n",
    "'''\n",
    "\n",
    "svc = SVC(kernel='linear')\n",
    "svc_score = get_score(svc,'SVC.pkl', data_train, target_train, data_test, target_test)\n",
    "\n",
    "print(svc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.9384398496240601\n",
      "F1-Score:  0.9509099782137138\n",
      "{'fit_time': array([0.00300169, 0.00500321, 0.00299811, 0.00199962, 0.00199986,\n",
      "       0.00299859, 0.00198698, 0.0019989 , 0.0019989 , 0.00199962]), 'score_time': array([0.00299859, 0.00200105, 0.00100136, 0.00199986, 0.00099993,\n",
      "       0.00100374, 0.00199437, 0.00100017, 0.00100112, 0.00200057]), 'test_accuracy': array([0.98245614, 0.92982456, 0.9122807 , 0.89473684, 0.94736842,\n",
      "       0.96491228, 0.96491228, 0.92982456, 0.94736842, 0.91071429]), 'test_f1': array([0.98550725, 0.94444444, 0.92957746, 0.91666667, 0.96      ,\n",
      "       0.97142857, 0.97297297, 0.94444444, 0.95652174, 0.92753623])}\n"
     ]
    }
   ],
   "source": [
    "cv_results = cross_validate(dtl, feat, target, cv=10, scoring=('accuracy', 'f1'))\n",
    "print(\"Accuracy: \", cv_results['test_accuracy'].mean())\n",
    "print(\"F1-Score: \", cv_results['test_f1'].mean())\n",
    "print(cv_results)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Penjelasan Hasil dari K- Fold Cross Validation\n",
    "\n",
    "Hasil k-fold cross validation dengan fold=10 menunjukkan bahwa model yang digunakan memiliki akurasi sebesar 0.9384 dan F1-Score sebesar 0.9509. Kedua nilai tersebut menunjukkan bahwa model tersebut memiliki performa yang baik dalam melakukan klasifikasi pada dataset yang digunakan.\n",
    "\n",
    "Bila dibandingkan dengan hasil perhitungan dari akurasi dan F1 score DecisionTreeClassifier , terlihat bahwa hasil evaluasi model menggunakan teknik K-Fold Cross Validation tidak menunjukkan perbedaan yang signifikan dengan model biasa. Hal ini menunjukkan bahwa model yang digunakan sebelumnya sudah cukup baik.\n",
    "\n",
    "Biasanya, penggunaan teknik K-Fold digunakan untuk memperbaiki model dengan akurasi yang rendah misal karena overfitting. Namun, pada kasus ini, model Decision Tree Classifier yang digunakan memiliki akurasi yang cukup baik, sehingga tidak perlu dilakukan perbaikan dengan teknik K-Fold Cross Validation.\n",
    "\n",
    "Selain itu, hasil dari k-fold cross validation tersebut juga menunjukkan informasi mengenai waktu yang dibutuhkan oleh model dalam melakukan training dan testing pada setiap fold. Rata-rata waktu training dan testing pada masing-masing fold adalah sekitar 0.002 detik.\n",
    "\n",
    "Selanjutnya, hasil k-fold cross validation juga menunjukkan performa model pada setiap fold dengan metrik akurasi dan F1-Score. Dari nilai-nilai tersebut, dapat dilihat bahwa performa model pada setiap fold cukup baik dengan nilai akurasi dan F1-Score yang tinggi pada sebagian besar fold.\n",
    "\n",
    "Secara keseluruhan, hasil k-fold cross validation dengan fold=10 menunjukkan bahwa model yang digunakan cukup baik dalam melakukan klasifikasi pada dataset breast cancer. Namun, bahwa hasil tersebut dapat dipengaruhi oleh faktor-faktor seperti metode preprocessing data, tuning parameter, dan pemilihan model yang digunakan. Oleh karena itu, perlu dilakukan evaluasi yang lebih detail untuk menentukan model yang paling optimal untuk dataset tersebut."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analisis Hasil Metrik Evaluasi\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "Skor akurasi yang mencapai 97% menunjukkan bahwa model ini bagus dalam mengklasifikasikan sebagian besar data baru. Skor presisi mencapai 97% yang merepresentasikan proporsi dari True-Positive menunjukkan model ini mempunyai proporsi yang tinggi untuk prediksi dengan hasil positif yang benar. Skor recall mencapai 98% menunjukkan bahwa model ini bisa mengidentifikasi sebagian besar sampel dengan kelas positif. F1 score yang dimiliki juga cukup tinggi mencapai 97% berarti model ini dapat dengan baik mengklasifikasikan data baru. Confusion matrix menunjukkan 44 true positive, 2 false positive, 1 false negative and 67 true negative. Hal ini berarti menunjukkan model mempunyai true positive rate yang tinggi dan false positive rate yang rendah. Hasil yang bagus berkaitan dengan pengaturan paramater criterion menjadi entropy agar menggunakan Information Gain"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID3\n",
    "{'accuracy_score': 0.956140350877193, \n",
    "'precision_score': 0.9565217391304348, \n",
    "'recall_score': 0.9705882352941176, \n",
    "'f1_score': 0.956140350877193, \n",
    "'confusion_matrix': array([[43,  3],\n",
    "       [ 2, 66]], dtype=int64)}\n",
    "\n",
    "##### Penjelasan Hasil \n",
    "\n",
    "1. accuracy_score: Merupakan nilai proporsi prediksi yang benar dari keseluruhan data yang dievaluasi. Nilai accuracy_score pada ID 3 sebesar 0.956140350877193, yang menunjukkan bahwa model berhasil memprediksi dengan benar sekitar 95,61% dari total data yang dievaluasi.\n",
    "\n",
    "2. precision_score: Merupakan nilai proporsi prediksi positif yang benar dari semua prediksi positif. Nilai precision_score pada ID3 sebesar 0.9565217391304348, yang menunjukkan bahwa model memiliki tingkat keakuratan yang baik dalam memprediksi kelas positif.\n",
    "\n",
    "3. recall_score: Merupakan nilai proporsi data positif yang diprediksi dengan benar dari semua data positif yang sebenarnya. Nilai recall_score pada ID3 sebesar 0.9705882352941176, yang menunjukkan bahwa model berhasil menemukan sekitar 97,06% data positif yang sebenarnya.\n",
    "\n",
    "4. f1_score: Merupakan nilai rata-rata harmonik antara precision dan recall. Nilai f1_score pada ID 3 sebesar 0.956140350877193, yang menunjukkan bahwa model memiliki tingkat akurasi yang baik dalam memprediksi kedua kelas.\n",
    "\n",
    "5. confusion_matrix: Merupakan matriks yang menunjukkan jumlah prediksi yang benar dan salah untuk setiap kelas. Pada ID 3, confusion matrix menunjukkan bahwa model memprediksi 43 data kelas negatif dengan benar (true negative), 3 data kelas negatif dengan salah (false positive), 2 data kelas positif dengan salah (false negative), dan 66 data kelas positif dengan benar (true positive).\n",
    "\n",
    "#### Formula\n",
    "##### id3 = Id3Estimator(prune=True, gain_ratio=True)\n",
    "Pada Id3 Estimator digunakan 2 parameter untuk tuning, yaitu prune dan gain_ratio yang keduanya menerima nilai boolean. Untuk gain_ratio yang bernilai True akan mengimplementasikan gain ratio untuk kalkulasi pada saat splitting tree. Pengimplementasian gain ratio ini menghasilkan nilai skor yang lebih baik, sedangkan prune yang bernilai True akan mengimplmentasikan pruning pada tree yang dibuat yang menghasilkan nilai skor yang lebih baik dibandingkan dengan tidak diimplementasikan. \n",
    "\n",
    "#### Perbandingan\n",
    "Jika dibandingkan dengan hasil sebelumnya, pada DTL, ID3 memiliki tingkat Accuracy dan F1 Score yang tidak jauh berbeda dengan model Decision Tree, bahkan terkadang lebih baik. Baik DTL, maupun ID3 memiliki cara kerja yang hampir sama, cara kerja model ID3 adalah  membangun pohon keputusan dari set data training. Pada awalnya, semua atribut yang tersedia digunakan untuk membagi set data menjadi subset yang lebih kecil berdasarkan nilai-nilai atribut. Atribut dengan Information Gain tertinggi dipilih sebagai node awal pohon keputusan. Pada setiap node baru, algoritma ini mengulangi proses yang sama untuk memilih atribut terbaik untuk membagi subset data pada node tersebut. Proses ini diulangi sampai semua data pada setiap cabang pohon keputusan memiliki label yang sama atau jumlah node maksimum tercapai. Hal tersebut dikarenakan model ID3 dapat juga ditranslasikan sebagai kumpulan logical rules yang dapat menggambarkan hubungan tersebut. Pada kasus dataset breast cancer, atribut yang terdapat di dalam tidak sepenuhnya independen antara satu sama lain, sehingga pembentukkan pohon keputusan akan memiliki simpul yang sedikit dan mudah untuk dipartisi.\n",
    "\n",
    "Keuntungan dari ID3 adalah kemampuannya untuk melakukan klasifikasi pada data yang memiliki banyak atribut. Selain itu, ID3 juga dapat menghasilkan pohon keputusan yang mudah diinterpretasikan. Namun, kelemahan dari algoritma ini adalah kemampuannya yang terbatas dalam menangani data yang memiliki nilai yang hilang atau data yang tidak berstruktur. Selain itu, algoritma ini juga cenderung overfitting pada data training yang kompleks. Oleh karena itu, variasi dari algoritma ID3 seperti C4.5 dan CART (Classification and Regression Trees) dikembangkan untuk mengatasi kelemahan dari ID3. Pada kasus ini, dataset breast_cancer tidak memiliki missing value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means\n",
    "\n",
    "{'accuracy_score': 0.868421052631579, \n",
    "'precision_score': 0.8271604938271605, \n",
    "'recall_score': 0.9852941176470589, \n",
    "'f1_score': 0.868421052631579, \n",
    "'confusion_matrix': array([[32, 14],\n",
    "       [ 1, 67]], dtype=int64)}\n",
    "\n",
    "#### Penjelasan Hasil\n",
    "1. accuracy_score: Menunjukkan akurasi dari model k-means dalam melakukan clustering. Nilai akurasi ini berkisar antara 0 dan 1, dimana semakin tinggi nilai akurasi semakin baik performa model. Pada hasil tersebut, nilai akurasi model adalah 0.868421052631579 atau sekitar 87%.\n",
    "\n",
    "2. precision_score: Menunjukkan seberapa banyak data yang terklasifikasi dengan benar ke dalam cluster yang sama (True Positives) dibandingkan dengan total data yang dinyatakan masuk ke dalam cluster tersebut (True Positives + False Positives). Nilai precision ini berkisar antara 0 dan 1, dimana semakin tinggi nilai precision semakin baik performa model. Pada hasil tersebut, nilai precision model adalah 0.8271604938271605 atau sekitar 83%.\n",
    "\n",
    "3. recall_score: Menunjukkan seberapa banyak data yang terklasifikasi dengan benar ke dalam cluster yang sama (True Positives) 4. dibandingkan dengan total data yang seharusnya masuk ke dalam cluster tersebut (True Positives + False Negatives). Nilai recall ini berkisar antara 0 dan 1, dimana semakin tinggi nilai recall semakin baik performa model. Pada hasil tersebut, nilai recall model adalah 0.9852941176470589 atau sekitar 99%.\n",
    "\n",
    "4. f1_score: Menggabungkan nilai precision dan recall menjadi satu nilai tunggal. Nilai f1-score ini berkisar antara 0 dan 1, dimana semakin tinggi nilai f1-score semakin baik performa model. Pada hasil tersebut, nilai f1-score model adalah 0.868421052631579 atau sekitar 87%.\n",
    "\n",
    "5. confusion_matrix: Merupakan tabel yang menunjukkan hasil prediksi model yang dibandingkan dengan nilai sebenarnya pada dataset. Pada hasil tersebut, confusion matrix menunjukkan bahwa terdapat 32 data yang diprediksi masuk ke dalam cluster 0 dan sebenarnya juga masuk ke dalam cluster 0 (True Negatives), 14 data yang diprediksi masuk ke dalam cluster 1 namun sebenarnya masuk ke dalam cluster 0 (False Positives), 1 data yang diprediksi masuk ke dalam cluster 0 namun sebenarnya masuk ke dalam cluster 1 (False Negatives), dan 67 data yang diprediksi masuk ke dalam cluster 1 dan sebenarnya juga masuk ke dalam cluster 1 (True Positives).\n",
    "\n",
    "\n",
    "Terlihat pada hasil ini, Algoritma Kmeans (unsupervised learning) ini memiliki nilai akurasi dan f_1 score terendah dibandingkan 5 algoritma pembelajaran yang lain. Hal ini disebabkan karena jumlah kluster default bernilai 8. \n",
    "\n",
    "Sedangkan pada dataset breast_cancer ini label hanyalah terdiri dari 2, tentunya hal tersebut akan menyebabkan hasil pembelajaran yang cukup jelek dibandingkan algoritma supervised. Untuk meningkatkan hal tersebut, digunakan parameter n_clusters bernilai 2. Selain itu, atribut max_iter yang merupakan jumlah iterasi maksimal yang dilakukan untuk pembelajaran di-assign dengan nilai 10000 dan random_state di-assign dengan nilai tertentu agar pada setiap kali dijalankan, menghasilkan hasil yang sama.\n",
    "\n",
    "\n",
    "#### Formula \n",
    "\n",
    "kmeans = KMeans(n_clusters=2, max_iter=10000, random_state=13) \n",
    "Terlihat pada formula diatas, terdapat 2 atribut, yakni n_cluster dan max_iter. Pada bagian sebelumnya telah disebutkan nilai default dari n_cluster adalah  bernilai 8. \n",
    "\n",
    "#### Perbandingan\n",
    "Hasilnya dengan algoritma ini relatif rendah. Disebabkan juga oleh sifat algoritma k-means itu sendiri yang dapat dipengaruhi oleh inisialisasi awal, jumlah kluster yang dipilih, dan kecocokan antara jumlah kluster dan struktur data. Selain itu, pada k-means, pengaruh dari nilai yang terlalu jauh dari pusat kluster dapat menjadi signifikan. Oleh karena itu, hasil dari k-means pada dataset breast cancer yang digunakan mungkin dapat ditingkatkan dengan mengoptimalkan parameter dan inisialisasi awal, serta dengan mengubah jumlah kluster dan/atau menggunakan metode klustering yang berbeda."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression\n",
    "{'accuracy_score': 0.9473684210526315, \n",
    "'precision_score': 0.9558823529411765, \n",
    "'recall_score': 0.9558823529411765, \n",
    "'f1_score': 0.9473684210526315, \n",
    "'confusion_matrix': array([[43,  3],\n",
    "       [ 3, 65]], dtype=int64)}\n",
    "\n",
    "\n",
    "#### Penjelasan Hasil\n",
    "1. accuracy_score: Menunjukkan tingkat keakuratan model dalam memprediksi nilai target. Nilai ini diperoleh dari rasio antara jumlah prediksi yang benar dengan jumlah total data. Pada kasus ini, nilai akurasi sebesar 0.9473684210526315 menunjukkan bahwa model dapat memprediksi nilai target dengan tingkat keakuratan sebesar 94,74%.\n",
    "\n",
    "2. precision_score: Menunjukkan tingkat ketepatan model dalam memprediksi nilai positif (class 1). Nilai ini diperoleh dari rasio antara jumlah prediksi benar positif dengan jumlah prediksi positif yang dilakukan oleh model. Pada kasus ini, nilai precision sebesar 0.9558823529411765 menunjukkan bahwa 95,59% dari prediksi positif yang dilakukan oleh model benar.\n",
    "\n",
    "3. recall_score: Menunjukkan tingkat kemampuan model dalam mengidentifikasi semua nilai positif yang ada (class 1). Nilai ini diperoleh dari rasio antara jumlah prediksi benar positif dengan jumlah keseluruhan nilai positif pada dataset. Pada kasus ini, nilai recall sebesar 0.9558823529411765 menunjukkan bahwa model dapat mengidentifikasi 95,59% dari seluruh nilai positif yang ada pada dataset.\n",
    "\n",
    "4. f1_score: Nilai f1_score menunjukkan rata-rata harmonik dari precision_score dan recall_score. F1 score berguna dalam situasi ketika terdapat trade-off antara precision dan recall. Pada kasus ini, nilai f1_score sebesar 0.9473684210526315 menunjukkan rata-rata harmonik dari precision_score dan recall_score sebesar 94,74%.\n",
    "\n",
    "5. confusion_matrix: Matriks ini menunjukkan jumlah prediksi yang benar dan salah yang dilakukan oleh model pada setiap class (class 0 dan class 1) dan digunakan untuk menghitung metrik evaluasi lainnya seperti accuracy, precision, dan recall. Pada kasus ini, matriks tersebut menunjukkan bahwa model memprediksi 43 data sebagai class 0 yang benar, 3 data sebagai class 0 yang salah, 3 data sebagai class 1 yang salah, dan 65 data sebagai class 1 yang benar.\n",
    "\n",
    "\n",
    "#### Formula\n",
    "LogisticRegression(max_iter=10000)\n",
    "\n",
    "Hasil evaluasi performa model Logistic Regression dapat berbeda-beda tergantung pada berbagai faktor seperti jenis dataset, pengaturan parameter model, ukuran dataset, dsb. \n",
    "\n",
    "Namun, dari hasil yang ditunjukkan sebelumnya, dapat dilihat bahwa model memiliki tingkat keakuratan yang cukup tinggi sebesar 94,74%. Selain itu, precision_score dan recall_score juga memiliki nilai yang cukup tinggi, yaitu 95,59%. Hal ini menunjukkan bahwa model dapat memprediksi nilai target dengan baik dan dapat mengidentifikasi sebagian besar nilai positif dengan baik.\n",
    "\n",
    "\n",
    "##### Perbandingan \n",
    "Jika melihat hasil, algoritma  ini berjalan dengan cukup baik tanpa perlu dilakukan tuning. Namun sklearn mengeluarkan warning bahwa fungsi prediksi belum mencapai konvergen. \n",
    "\n",
    "Hal tersebut dapat diatasi dengan meningkatkan proses iterasi regresi agar fungsi prediksi dapat masuk kedalam daerah konvergen yang didefinisikan sklearn.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multilayer Perceptron (MLP)\n",
    "\n",
    "{'accuracy_score': 0.956140350877193, 'precision_score': 0.9846153846153847, 'recall_score': 0.9411764705882353, 'f1_score': 0.956140350877193, 'confusion_matrix': array([[45,  1],\n",
    "       [ 4, 64]], dtype=int64)}\n",
    "\n",
    "#### Penjelasan Hasil\n",
    "\n",
    "1. accuracy_score: Menunjukkan akurasi dari model MLP dalam melakukan klasifikasi. Nilai akurasi ini berkisar antara 0 dan 1, dimana semakin tinggi nilai akurasi semakin baik performa model. Pada hasil tersebut, nilai akurasi model adalah 0.956140350877193 atau sekitar 95%.\n",
    "\n",
    "2. precision_score: Merupakan nilai proporsi prediksi positif yang benar dari semua prediksi positif. Nilai precision_score pada MLP sebesar 0.9846153846153847, yang menunjukkan bahwa model memiliki tingkat keakuratan yang baik dalam memprediksi kelas positif.\n",
    "\n",
    "3. recall_score: Merupakan nilai proporsi data positif yang diprediksi dengan benar dari semua data positif yang sebenarnya. Nilai recall_score pada MLP sebesar 0.9411764705882353, yang menunjukkan bahwa model berhasil menemukan sekitar 94,11% data positif yang sebenarnya.\n",
    "\n",
    "4. f1_score: Merupakan nilai rata-rata harmonik antara precision dan recall. Nilai f1_score pada MLP sebesar 0.956140350877193, yang menunjukkan bahwa model memiliki tingkat akurasi yang baik dalam memprediksi kedua kelas.\n",
    "\n",
    "5. confusion_matrix: Merupakan matriks yang menunjukkan jumlah prediksi yang benar dan salah untuk setiap kelas. \n",
    "Confusion matrix menunjukkan bahwa model dengan benar mengklasifikasikan 32 sampel sebagai negatif dan 67 sampel sebagai positif, tetapi salah mengklasifikasikan 14 sampel negatif sebagai positif dan hanya 1 sampel positif sebagai negatif. Hal ini menunjukkan bahwa model tersebut memiliki tingkat false positive yang tinggi dan tingkat false negative yang relatif rendah\n",
    "\n",
    "#### Formula \n",
    "\n",
    "MLPClassifier(max_iter=10000000, solver=\"lbfgs\")\n",
    "\n",
    "Parameter solver di-_set_ sebagai \"lbfgs\". Limited-memory Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) digunakan untuk mengoptimasi weights parameter bias dari network. Selain itu, optimizer ini konvergen dengan lebih cepat dan performanya lebih bagus untuk dataset yang digunakan. Hal ini karena L-BFGS bagus untuk jumlah data yang kecil."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)\n",
    "\n",
    "{'accuracy_score': 0.9649122807017544, 'precision_score': 0.9705882352941176, 'recall_score': 0.9705882352941176, 'f1_score': 0.9649122807017544, 'confusion_matrix': array([[44,  2],\n",
    "       [ 2, 66]], dtype=int64)}\n",
    "\n",
    "#### Penjelasan Hasil \n",
    "\n",
    "1. accuracy_score: Menunjukkan akurasi dari model SVM dalam melakukan klasifikasi. Nilai akurasi ini berkisar antara 0 dan 1, dimana semakin tinggi nilai akurasi semakin baik performa model. Pada hasil tersebut, nilai akurasi model adalah 0.9649122807017544 atau sekitar 96%.\n",
    "\n",
    "2. precision_score: Merupakan nilai proporsi prediksi positif yang benar dari semua prediksi positif. Nilai precision_score pada SVM sebesar 0.9705882352941176, yang menunjukkan bahwa model memiliki tingkat keakuratan yang baik dalam memprediksi kelas positif.\n",
    "\n",
    "3. recall_score: Merupakan nilai proporsi data positif yang diprediksi dengan benar dari semua data positif yang sebenarnya. Nilai recall_score pada SVM sebesar 0.9705882352941176, yang menunjukkan bahwa model berhasil menemukan sekitar 97,05% data positif yang sebenarnya.\n",
    "\n",
    "4. f1_score: Merupakan nilai rata-rata harmonik antara precision dan recall. Nilai f1_score pada SVM sebesar 0.9649122807017544, yang menunjukkan bahwa model memiliki tingkat akurasi yang baik dalam memprediksi kedua kelas.\n",
    "\n",
    "5. confusion_matrix: Merupakan matriks yang menunjukkan jumlah prediksi yang benar dan salah untuk setiap kelas. \n",
    "Berdasarkan confusion matrix, dapat dilihat bahwa model melakukan 2 kali kesalahan dalam mengklasifikasikan data kelas negatif sebagai kelas positif, dan juga melakukan 2 kali kesalahan dalam mengklasifikasikan data kelas positif sebagai kelas negatif. Namun secara keseluruhan, model SVM berhasil mengklasifikasikan data dengan sangat baik.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e5b92b0101f41b621413ac1b2121fd9024477e71c5712f9943f356685bf952d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
